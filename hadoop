1） Hadoop生态
Hadoop 是一个很大的生态，包含了一系列的数据处理工具，最基础的是 HDFS 和 MapReduce，前者可以简单理解为分布式文件系统，用来存数据，后者用来做计算。
Spark 等实现的是 MapReduce 的功能，或者说 MapReduce 的优化。
Hadoop 还有一个常见的组件是资源调度框架 YARN ，Spark 等都可以运行在 YARN 上。

构建于 HDFS 上的 HBase，
类 SQL 的 Hive 数据操纵语言，
构建于 MapReduce 之上的 Mahout 机器学习框架，
序列化数据的 Avro，日志收集 Flume 等

2） Why Hadoop?

小数据情况下，数据库的 B 树很快，但数据量一多，涉及大量的排序和合并，MapReduce 的优势就体现出来了！



3） 有一个新的数据分析引擎 ClickHouse (https://clickhouse.yandex/) 据说非常之快，并且不依赖于 Hadoop，有兴趣的可以了解下...
